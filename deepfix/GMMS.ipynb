{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:QualDR dataset labels unavailable because pyjq not installed\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Boilerplate to implement training different networks on different datasets\n",
    "with varying config.\n",
    "\n",
    "I wish a machine could automate setting up decent baseline models and datasets\n",
    "\"\"\"\n",
    "#  import json\n",
    "import os\n",
    "from os.path import exists\n",
    "import pampy\n",
    "from simple_parsing import ArgumentParser, choice\n",
    "from simplepytorch import datasets as D\n",
    "from simplepytorch import trainlib as TL\n",
    "from simplepytorch import metrics\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from typing import Union, Optional\n",
    "import dataclasses as dc\n",
    "import numpy as np\n",
    "import torch as T\n",
    "import torchvision.transforms as tvt\n",
    "import torch\n",
    "from torch import optim, nn\n",
    "from torchvision import models, transforms\n",
    "\n",
    "from deepfix.models import get_effnetv2, get_resnet, get_efficientnetv1, get_DeepFixEnd2End, DeepFixMLP\n",
    "from deepfix.models.ghaarconv import convert_conv2d_to_gHaarConv2d\n",
    "from deepfix.init_from_distribution import init_from_beta, reset_optimizer\n",
    "from deepfix import deepfix_strategies as dfs\n",
    "import pytorch_wavelets as pyw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device = cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.io\n",
    "# from ipynb.fs.defs.q2 import *\n",
    "import sklearn\n",
    "import torch\n",
    "import torchvision.datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "# YOUR CODE HERE\n",
    "# Use GPU if available, otherwise stick with cpu\n",
    "use_cuda = torch.cuda.is_available()\n",
    "torch.manual_seed(123)\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "print(\"device = {}\".format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODELS = {\n",
    "    ('effnetv2', str, str, str): (\n",
    "        lambda pretrain, in_ch, out_ch: get_effnetv2(pretrain, int(in_ch), int(out_ch))),\n",
    "    ('resnet50', str, str, str): (\n",
    "        lambda pretrain, in_ch, out_ch: get_resnet('resnet50', pretrain, int(in_ch), int(out_ch))),\n",
    "    ('resnet18', str, str, str): (\n",
    "        lambda pretrain, in_ch, out_ch: get_resnet('resnet18', pretrain, int(in_ch), int(out_ch))),\n",
    "    ('efficientnet-b0', str, str, str): (\n",
    "        lambda pretrain, in_ch, out_ch: get_efficientnetv1('efficientnet-b0', pretrain, int(in_ch), int(out_ch))),\n",
    "    ('efficientnet-b1', str, str, str): (\n",
    "        lambda pretrain, in_ch, out_ch: get_efficientnetv1('efficientnet-b1', pretrain, int(in_ch), int(out_ch))),\n",
    "    ('waveletres18', str, str, str): lambda pretrain, in_ch, out_ch: R(\n",
    "        pretrain, int(in_ch), int(out_ch)),\n",
    "    ('waveletmlp', str, str, str, str, str, str, str): (\n",
    "        lambda mlp_channels, in_ch, out_ch, wavelet_levels, patch_size, in_ch_mul, mlp_depth: get_DeepFixEnd2End(\n",
    "            int(in_ch), int(out_ch),\n",
    "            in_ch_multiplier=int(in_ch_mul), wavelet='db1',\n",
    "            wavelet_levels=int(wavelet_levels), wavelet_patch_size=int(patch_size),\n",
    "            mlp_depth=int(mlp_depth), mlp_channels=int(mlp_channels),\n",
    "            mlp_fix_weights='none', mlp_activation=None)\n",
    "        ),\n",
    "\n",
    "    #  ('waveletres18v2', str, str, str): lambda pretrain, in_ch, out_ch: (\n",
    "        #  DeepFixCompression(levels=8, wavelet='coif1', patch_size=1),\n",
    "        #  R2(pretrain, int(in_ch), int(out_ch))),\n",
    "}\n",
    "\n",
    "\n",
    "class R(T.nn.Module):\n",
    "    def __init__(self, pretrain, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.r = get_resnet('resnet18', pretrain, in_ch, out_ch,)\n",
    "        self.dwt = pyw.DWT(J=8, wave='coif1', mode='zero')\n",
    "\n",
    "    @staticmethod\n",
    "    def wavelet_coefficients_as_tensorimage(approx, detail, normalize=False):\n",
    "        B,C = approx.shape[:2]\n",
    "        fixed_dims = approx.shape[:-2] # num images in minibatch, num channels, etc\n",
    "        output_shape = fixed_dims + (\n",
    "            detail[0].shape[-2]*2,  # input img height\n",
    "            detail[0].shape[-1]*2)  # input img width\n",
    "        im = T.zeros(output_shape, device=approx.device, dtype=approx.dtype)\n",
    "        if normalize:\n",
    "            norm11 = lambda x: (x / max(x.min()*-1, x.max()))  # into [-1,+1] preserving sign\n",
    "            #  approx = norm11(approx)\n",
    "        im[..., :approx.shape[-2], :approx.shape[-1]] = approx if approx is not None else 0\n",
    "        for level in detail:\n",
    "            lh, hl, hh = level.unbind(-3)\n",
    "            h,w = lh.shape[-2:]\n",
    "            if normalize:\n",
    "                lh, hl, hh = [norm11(x) for x in [lh, hl, hh]]\n",
    "            #  im[:h, :w] = approx\n",
    "            im[..., 0:h, w:w+w] = lh  # horizontal\n",
    "            im[..., h:h+h, :w] = hl  # vertical\n",
    "            im[..., h:h+h, w:w+w] = hh  # diagonal\n",
    "        return im\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.wavelet_coefficients_as_tensorimage(*self.dwt(x))\n",
    "        return self.r(x)\n",
    "\n",
    "\n",
    "class R2(T.nn.Module):\n",
    "    def __init__(self, pretrain, in_ch, out_ch):\n",
    "        super().__init__()\n",
    "        self.r = get_resnet('resnet18', pretrain, in_ch, out_ch,)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B,C,H = x.shape\n",
    "        x = x.unsqueeze(-1).repeat(1,1,1,H)\n",
    "        return self.r(x)\n",
    "\n",
    "\n",
    "class LossCheXpertIdentity(T.nn.Module):\n",
    "    def __init__(self, N):\n",
    "        super().__init__()\n",
    "        self.bce = T.nn.BCEWithLogitsLoss()\n",
    "        self.N = N\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        # absolute max possible num patients in chexpert is 223414\n",
    "        # but let's just hash them into a smaller number of bins via modulo N\n",
    "        assert self.N == yhat.shape[1], \\\n",
    "                f'note: model must have {self.N} binary predictions per sample'\n",
    "        y_onehot = y.new_zeros(y.shape[0], self.N, dtype=T.float\n",
    "                               ).scatter_(1, y.long()%self.N, 1)\n",
    "        return self.bce(yhat[:, -1], y_onehot[:, -1])\n",
    "\n",
    "\n",
    "class LossCheXpertUignore(T.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.bce = T.nn.BCEWithLogitsLoss()\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        ignore = (y != 2)  # ignore uncertainty labels\n",
    "        return self.bce(yhat[ignore], y[ignore])\n",
    "\n",
    "\n",
    "def loss_intelmobileodt(yhat, y):\n",
    "    \"\"\"BCE Loss with class balancing weights.\n",
    "\n",
    "    Not sure this actually helps\n",
    "\n",
    "    because Type 2 is the hardest class, it\n",
    "    has the most samples, and it separates Type 1 from Type 3.  Arguably, Type 2\n",
    "    samples are on the decision boundary between Type 1 and 3.\n",
    "    Class balancing weights make it harder to focus on class 2.\n",
    "    \"\"\"\n",
    "    #  assert y.shape == yhat.shape, 'sanity check'\n",
    "    #  assert y.dtype == yhat.dtype, 'sanity check'\n",
    "\n",
    "    # class distribution of stage='train'\n",
    "    w = T.tensor([249, 781, 450], dtype=y.dtype, device=y.device)\n",
    "    w = (w.max() / w).reshape(1, 3)\n",
    "    # w can have any of the shapes:  (B,1) or (1,C) or (B,C)\n",
    "    #  return T.nn.functional.binary_cross_entropy_with_logits(yhat, y, weight=w)\n",
    "    return T.nn.functional.cross_entropy(yhat, y, weight=w)\n",
    "    # can't apply focal loss unless do it manually.\n",
    "\n",
    "\n",
    "def onehot(y, nclasses):\n",
    "    return T.zeros((y.numel(), nclasses), dtype=y.dtype, device=y.device)\\\n",
    "            .scatter_(1, y.unsqueeze(1), 1)\n",
    "\n",
    "\n",
    "def _upsample_pad_minibatch_imgs_to_same_size(batch, target_is_segmentation_mask=False):\n",
    "    \"\"\"a collate function for a dataloader of (x,y) samples.  \"\"\"\n",
    "    shapes = [item[0].shape for item in batch]\n",
    "    H = max(h for c,h,w in shapes)\n",
    "    W = max(w for c,h,w in shapes)\n",
    "    X, Y = [], []\n",
    "    for item in batch:\n",
    "        h,w = item[0].shape[1:]\n",
    "        dh, dw = (H-h), (W-w)\n",
    "        padding = (dw//2, dw-dw//2, dh//2, dh-dh//2, )\n",
    "        X.append(T.nn.functional.pad(item[0], padding))\n",
    "        if target_is_segmentation_mask:\n",
    "            Y.append(T.nn.functional.pad(item[1], padding))\n",
    "        else:\n",
    "            Y.append(item[1])\n",
    "    return T.stack(X), T.stack(Y)\n",
    "\n",
    "\n",
    "def get_dset_chexpert(train_frac=.8, val_frac=.2, small=False,\n",
    "                      labels:str='diagnostic', num_identities=None):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        labels:  either \"diagnostic\" (the 14 classes defined as\n",
    "            D.CheXpert.LABELS_DIAGNOSTIC) or \"identity\" (\"patient\", \"study\",\n",
    "            \"view\", \"index\")\n",
    "        small:  whether to use CheXpert_Small dataset (previously downsampled\n",
    "            images) or the fully size dataset.\n",
    "        num_identities:  used only if labels='identity'.  If\n",
    "            num_identities=1000, then all patients get identified as coming\n",
    "            from precisely 1 of 1000 bins.\n",
    "\n",
    "    Returns:\n",
    "        (\n",
    "        {'train_dset': ..., 'val_dset': ..., 'test_dset': ...,\n",
    "         'train_loader': ..., 'val_loader': ..., 'test_loader': ...\n",
    "         },\n",
    "\n",
    "        ('Pneumonia', 'Cardiomegaly', ...)  # class names defined by `labels`\n",
    "        )\n",
    "    \"\"\"\n",
    "    _label_cleanup_dct = dict(D.CheXpert.LABEL_CLEANUP_DICT)\n",
    "    if labels == 'diagnostic':\n",
    "        class_names = D.CheXpert.LABELS_DIAGNOSTIC\n",
    "        for k in class_names:\n",
    "            _label_cleanup_dct[k][np.nan] = 0  # remap missing value to negative\n",
    "        get_ylabels = lambda dct: \\\n",
    "                D.CheXpert.format_labels(dct, labels=class_names).float()\n",
    "    elif labels == 'identity':\n",
    "        class_names = list(range(num_identities))\n",
    "        get_ylabels = lambda dct: \\\n",
    "                (D.CheXpert.format_labels(dct, labels=['index']) % num_identities).long()\n",
    "    else:\n",
    "        raise NotImplementedError(f\"unrecognized labels: {labels}\")\n",
    "    kws = dict(\n",
    "        img_transform=tvt.Compose([\n",
    "            #  tvt.RandomCrop((512, 512)),\n",
    "            tvt.ToTensor(),  # full res 1024x1024 imgs\n",
    "            tvt.Resize((224, 224)),\n",
    "            tvt.Lambda(lambda x: x.repeat(3, 1, 1)),\n",
    "            \n",
    "        ]),\n",
    "        getitem_transform=lambda dct: (dct['image'], get_ylabels(dct)),\n",
    "        label_cleanup_dct=_label_cleanup_dct,\n",
    "    )\n",
    "    if small:\n",
    "        kls = D.CheXpert_Small\n",
    "    else:\n",
    "        kls = D.CheXpert\n",
    "\n",
    "    train_dset = kls(dataset_dir=\"../data/CheXpert-v1.0-small/\",use_train_set=True, **kws)  #Edited Elvin\n",
    "\n",
    "    N = len(train_dset)\n",
    "    if train_frac + val_frac == 1:\n",
    "        nsplits = [N - int(N*val_frac), int(N*val_frac), 0]\n",
    "    else:\n",
    "        a,b = int(N*train_frac), int(N*val_frac)\n",
    "        nsplits = [a,b, N-a-b]\n",
    "    train_dset, val_dset, _ = T.utils.data.random_split(train_dset, nsplits)\n",
    "    test_dset = kls(dataset_dir=\"../data/CheXpert-v1.0-small/\",use_train_set=False, **kws) #Edited Elvin\n",
    "    batch_dct = dict(\n",
    "        batch_size=1, collate_fn=_upsample_pad_minibatch_imgs_to_same_size,\n",
    "        num_workers=int(os.environ.get(\"num_workers\", 4)))  # upsample pad must take time\n",
    "    train_loader=DataLoader(train_dset, shuffle=True, **batch_dct)\n",
    "    val_loader=DataLoader(val_dset, **batch_dct)\n",
    "    test_loader=DataLoader(test_dset, **batch_dct)\n",
    "    return (dict(\n",
    "        train_dset=train_dset, val_dset=val_dset, test_dset=test_dset,\n",
    "        train_loader=train_loader, val_loader=val_loader, test_loader=test_loader,\n",
    "    ), class_names)\n",
    "\n",
    "\n",
    "\n",
    "def match(spec:str, dct:dict):\n",
    "    return pampy.match(spec.split(':'), *(x for y in dct.items() for x in y))\n",
    "\n",
    "\n",
    "def get_model_opt_loss(\n",
    "        model_spec:str, opt_spec:str, loss_spec:str, regularizer_spec:str,\n",
    "        device:str) -> dict[str, Union[T.nn.Module, T.optim.Optimizer]]:\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        model_spec: a string of form,\n",
    "            \"model_name:pretraining:in_channels:out_classes\".  For example:\n",
    "            \"effnetv2:untrained:1:5\"\n",
    "        opt_spec: Specifies how to create optimizer.\n",
    "            First value is a pytorch Optimizer in T.optim.*.\n",
    "            Other values are numerical parameters.\n",
    "            Example: \"SGD:lr=.003:momentum=.9\"\n",
    "        device: e.g. 'cpu' or 'gpu'\n",
    "    Returns:\n",
    "        a pytorch model and optimizer\n",
    "    \"\"\"\n",
    "    mdl = match(model_spec, MODELS)\n",
    "    mdl = mdl.to(device, non_blocking=True)\n",
    "    optimizer = reset_optimizer(opt_spec, mdl)\n",
    "    loss_fn = match(loss_spec, LOSS_FNS)\n",
    "    if regularizer_spec != 'none':\n",
    "        loss_fn = RegularizedLoss(mdl, loss_fn, regularizer_spec)\n",
    "    return dict(model=mdl, optimizer=optimizer, loss_fn=loss_fn)\n",
    "\n",
    "\n",
    "class RegularizedLoss(T.nn.Module):\n",
    "    def __init__(self, model, lossfn, regularizer_spec:str):\n",
    "        super().__init__()\n",
    "        self.lossfn = lossfn\n",
    "        self.regularizer_spec = regularizer_spec\n",
    "        if regularizer_spec == 'none':\n",
    "            self.regularizer = lambda *y: 0\n",
    "        elif regularizer_spec.startswith('deepfixmlp:'):\n",
    "            lbda = float(regularizer_spec.split(':')[1])\n",
    "            self.regularizer = lambda *y: (\n",
    "                float(lbda) * DeepFixMLP.get_VecAttn_regularizer(model))\n",
    "        else:\n",
    "            raise NotImplementedError(regularizer_spec)\n",
    "\n",
    "    def forward(self, yhat, y):\n",
    "        return self.lossfn(yhat, y) + self.regularizer(yhat, y)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'RegularizedLoss<{repr(self.lossfn)},{self.regularizer_spec}>'\n",
    "\n",
    "\n",
    "def get_dset_loaders_resultfactory(dset_spec:str) -> dict:\n",
    "    dct, class_names = match(dset_spec, DSETS)\n",
    "    if any(dset_spec.startswith(x) for x in {'intel_mobileodt:',\n",
    "                                             'chexpert_small_ID:'}):\n",
    "        #  dct['result_factory'] = lambda: TL.MultiLabelBinaryClassification(\n",
    "                #  class_names, binarize_fn=lambda yh: (T.sigmoid(yh)>.5).long())\n",
    "        dct['result_factory'] = lambda: TL.MultiClassClassification(\n",
    "                len(class_names), binarize_fn=lambda yh: yh.softmax(1).argmax(1))\n",
    "    elif any(dset_spec.startswith(x) for x in {'chexpert:', 'chexpert_small:'}):\n",
    "        dct['result_factory'] = lambda: CheXpertMultiLabelBinaryClassification(\n",
    "            class_names, binarize_fn=lambda yh: (yh.sigmoid()>.5).long(), report_avg=True)\n",
    "    else:\n",
    "        raise NotImplementedError(f\"I don't know how to create the result factory for {dset_spec}\")\n",
    "    return dct\n",
    "\n",
    "class CheXpertMultiLabelBinaryClassification(TL.MultiLabelBinaryClassification):\n",
    "    def update(self, yhat, y, loss) -> None:\n",
    "        self.num_samples += yhat.shape[0]\n",
    "        self.loss += loss.item()\n",
    "        assert yhat.shape == y.shape\n",
    "        assert yhat.ndim == 2 and yhat.shape[1] == len(self._cms), \"sanity check: model outputs expected prediction shape\"\n",
    "        binarized = self._binarize_fn(yhat)\n",
    "        assert binarized.dtype == T.long, 'sanity check binarize fn'\n",
    "        assert binarized.shape == y.shape, 'sanity check binarize fn'\n",
    "        ignore = (y != 2)  # ignore uncertainty labels\n",
    "        for i, (kls, cm) in enumerate(self._cms.items()):\n",
    "            rows = ignore[:, i]\n",
    "            if rows.sum() == 0:\n",
    "                continue  # don't update a confusion matrix if all data for this class is ignored\n",
    "            cm += metrics.confusion_matrix(y[rows, i], binarized[rows, i], num_classes=2).cpu()\n",
    "\n",
    "\n",
    "def get_deepfix_train_strategy(args:'TrainOptions'):\n",
    "    deepfix_spec = args.deepfix\n",
    "    if deepfix_spec == 'off':\n",
    "        return TL.train_one_epoch\n",
    "    elif deepfix_spec.startswith('reinit:'):\n",
    "        _, N, P, R = deepfix_spec.split(':')\n",
    "        return dfs.DeepFix_TrainOneEpoch(int(N), float(P), int(R), TL.train_one_epoch)\n",
    "    elif deepfix_spec.startswith('dhist:'):\n",
    "        fp = deepfix_spec.split(':', 1)[1]\n",
    "        assert exists(fp), f'histogram file not found: {fp}'\n",
    "        return dfs.DeepFix_DHist(fp)\n",
    "    elif deepfix_spec.startswith('dfhist:'):\n",
    "        fp = deepfix_spec.split(':', 1)[1]\n",
    "        assert exists(fp), f'histogram file not found: {fp}'\n",
    "        return dfs.DeepFix_DHist(fp, fixed=True)\n",
    "    elif deepfix_spec == 'fixed':\n",
    "        return dfs.DeepFix_DHist('', fixed=True, init_with_hist=False)\n",
    "    elif deepfix_spec.startswith('beta:'):\n",
    "        alpha, beta = deepfix_spec.split(':')[1:]\n",
    "        return dfs.DeepFix_LambdaInit(\n",
    "            lambda cfg: init_from_beta(cfg.model, float(alpha), float(beta)))\n",
    "    elif deepfix_spec.startswith('ghaarconv2d:'):\n",
    "        ignore_layers = deepfix_spec.split(':')[1].split(',')\n",
    "        return dfs.DeepFix_LambdaInit(\n",
    "            lambda cfg: (\n",
    "                print(f'initialize {deepfix_spec}'),\n",
    "                convert_conv2d_to_gHaarConv2d(cfg.model, ignore_layers=ignore_layers),\n",
    "                reset_optimizer(args.opt, cfg.model),\n",
    "                print(cfg.model)\n",
    "            ))\n",
    "    else:\n",
    "        raise NotImplementedError(deepfix_spec)\n",
    "\n",
    "\n",
    "def train_config(args:'TrainOptions') -> TL.TrainConfig:\n",
    "    return TL.TrainConfig(\n",
    "        **get_model_opt_loss(\n",
    "            args.model, args.opt, args.lossfn, args.loss_reg, args.device),\n",
    "        **get_dset_loaders_resultfactory(args.dset),\n",
    "        device=args.device,\n",
    "        epochs=args.epochs,\n",
    "        start_epoch=args.start_epoch,\n",
    "        train_one_epoch=get_deepfix_train_strategy(args),\n",
    "        experiment_id=args.experiment_id,\n",
    "    )\n",
    "\n",
    "\n",
    "@dc.dataclass\n",
    "class TrainOptions:\n",
    "    \"\"\"High-level configuration for training PyTorch models\n",
    "    on the IntelMobileODTCervical dataset.\n",
    "    \"\"\"\n",
    "    epochs:int = 50\n",
    "    start_epoch:int = 0  # if \"--start_epoch 1\", then don't evaluate perf before training.\n",
    "    device:str = 'cuda' if T.cuda.is_available() else 'cpu'\n",
    "    dset:str = None #choice(\n",
    "        #  'intel_mobileodt:train:val:test:v1',\n",
    "        #  'intel_mobileodt:train+additional:val:test:v1',\n",
    "        #  'intel_mobileodt:train+additional:noval:test:v1',\n",
    "        #  'chexpert:.8:.2', 'chexpert:.01:.01', 'chexpert:.001:.001',\n",
    "        #  'chexpert_small:.8:.2', 'chexpert_small:.01:.01',\n",
    "        #   'chexpert_small:.001:.001',\n",
    "        #  default='intel_mobileodt:train:val:test:v1')\n",
    "    opt:str = 'SGD:lr=.001:momentum=.9:nesterov=1'\n",
    "    lossfn:str = None  # choices:\n",
    "        #  'BCEWithLogitsLoss',\n",
    "        #  'CrossEntropyLoss', \n",
    "        #  'CE_intelmobileodt',\n",
    "        #  'chexpert_uignore', \n",
    "        #  'chexpert_identity:N' for some N=num_identities predicted by model (compared to identities y%N)\n",
    "    loss_reg:str = 'none'  # Optionally add a regularizer to the loss.  loss + reg.  Accepted values:  'none', 'deepfixmlp:X' where X is a positive float denoting the lambda in l1 regularizer\n",
    "    model:str = 'resnet18:imagenet:3:3'  # Model specification adheres to the template \"model_name:pretraining:in_ch:out_ch\"\n",
    "    deepfix:str = 'off'  # DeepFix Re-initialization Method.\n",
    "                         #  \"off\" or \"reinit:N:P:R\" or \"d[f]hist:path_to_histogram.pth\"\n",
    "                         #  or \"beta:A:B\" for A,B as (float) parameters of the beta distribution\n",
    "                         # 'ghaarconv2d:layer1,layer2' Replaces all spatial convolutions with GHaarConv2d layer except the specified layers\n",
    "    experiment_id:str = os.environ.get('run_id', 'debugging')\n",
    "    prune:str = 'off'\n",
    "\n",
    "    def execute(self):\n",
    "        cfg = train_config(self)\n",
    "        cfg.train(cfg)\n",
    "\n",
    "\n",
    "def main():\n",
    "    p = ArgumentParser()\n",
    "    p.add_arguments(TrainOptions, dest='TrainOptions')\n",
    "#     for patch_size in [1,32]:\n",
    "#         for wavelet_level in [1,2,3,4,5,6,7,8,9]:    \n",
    "#             try:\n",
    "    in_ch, out_ch = 3, 3\n",
    "    model_params = \"resnet18:imagenet:\"+str(in_ch)+\":\"+str(in_ch)    \n",
    "    \n",
    "#     model_params = \"waveletmlp:300:1:14:\"+str(patch_size)+\":\"+str(wavelet_level)+\":1:2\"\n",
    "    exp_id = 'model_'+model_params+'_in_ch_'+str(in_ch)+'out_ch_'+str(in_ch)#+'_patch_size_' + str(patch_size) + '_level_' + str(wavelet_level)\n",
    "    args = p.parse_args([\"--dset\", \"chexpert_small:.01:.01\", \"--opt\", \"Adam:lr=0.001\", \"--lossfn\", \"chexpert_uignore\", \"--model\", model_params, \"--loss_reg\", \"none\",\"--experiment_id\",exp_id]).TrainOptions\n",
    "\n",
    "    print(args)\n",
    "    cfg = train_config(args)\n",
    "\n",
    "# python deepfix/train.py --dset chexpert_small:.01:.01 --opt Adam:lr=0.001 --lossfn chexpert_uignore --model waveletmlp:300:1:14:7:1:1:2 --loss_reg none    \n",
    "\n",
    "    if args.prune != 'off':\n",
    "        assert args.prune.startswith('ChannelPrune:')\n",
    "        raise NotImplementedError('code is a bit hardcoded, so it is not available without hacking on it.')\n",
    "        print(args.prune)\n",
    "        from explainfix import channelprune\n",
    "        from deepfix.weight_saliency import costfn_multiclass\n",
    "        a = sum([x.numel() for x in cfg.model.parameters()])\n",
    "        channelprune(cfg.model, pct=5, grad_cost_fn=costfn_multiclass,\n",
    "                     loader=cfg.train_loader, device=cfg.device, num_minibatches=10)\n",
    "        b = sum([x.numel() for x in cfg.model.parameters()])\n",
    "        assert a/b != 1\n",
    "        print(f'done channelpruning.  {a/b}')\n",
    "\n",
    "    cfg.train(cfg)\n",
    "#             except Exception as e:\n",
    "#                 print(\"=================================================================================================\")\n",
    "#                 print(e)\n",
    "#                 print(\"=================================================================================================\")\n",
    "            \n",
    "    print('+++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++')\n",
    "    #  import IPython ; IPython.embed() ; import sys ; sys.exit()\n",
    "\n",
    "    #  with T.profiler.profile(\n",
    "    #      activities=[\n",
    "    #          T.profiler.ProfilerActivity.CPU,\n",
    "    #          T.profiler.ProfilerActivity.CUDA,\n",
    "    #      ], with_modules=True,\n",
    "    #  ) as p:\n",
    "    #      cfg.train(cfg)\n",
    "    #  print(p.key_averages().table(\n",
    "    #      sort_by=\"self_cuda_time_total\", row_limit=-1))\n",
    "\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_dset': <torch.utils.data.dataset.Subset at 0x154056620250>,\n",
       " 'val_dset': <torch.utils.data.dataset.Subset at 0x1540566204f0>,\n",
       " 'test_dset': <simplepytorch.datasets.chexpert.CheXpert at 0x154056527d00>,\n",
       " 'train_loader': <torch.utils.data.dataloader.DataLoader at 0x154055fe44c0>,\n",
       " 'val_loader': <torch.utils.data.dataloader.DataLoader at 0x15404f1494f0>,\n",
       " 'test_loader': <torch.utils.data.dataloader.DataLoader at 0x15404f149e50>}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d,l = get_dset_chexpert()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset_loader = d['train_loader']\n",
    "valset_loader = d['val_loader']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178732"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trainset_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet18(pretrained=True)\n",
    "# model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = torch.nn.Sequential(*list(model.children())[:-1])\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else \"cpu\")\n",
    "new_model = new_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate the Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 178732/178732 [29:43<00:00, 100.21it/s] \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "# Will contain the feature\n",
    "X_train = []\n",
    "Y_train = []\n",
    "for data in tqdm(trainset_loader):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    with torch.no_grad():\n",
    "        # Extract the feature from the image\n",
    "        feature = new_model(inputs)\n",
    "        X_train.append(feature.cpu().detach().numpy().reshape(512))\n",
    "        Y_train.append(labels.cpu().detach().numpy()[0])\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 44682/44682 [06:32<00:00, 113.81it/s]\n"
     ]
    }
   ],
   "source": [
    "# Will contain the feature\n",
    "X_test = []\n",
    "Y_test = []\n",
    "for data in tqdm(valset_loader):\n",
    "    inputs, labels = data\n",
    "    inputs = inputs.to(device)\n",
    "    labels = labels.to(device)\n",
    "    with torch.no_grad():\n",
    "        # Extract the feature from the image\n",
    "        feature = new_model(inputs)\n",
    "#         print(feature.size())\n",
    "        # Convert to NumPy Array, Reshape it, and save it to features variable\n",
    "        X_test.append(feature.cpu().detach().numpy().reshape(512))\n",
    "        Y_test.append(labels.cpu().detach().numpy()[0])\n",
    "#         features.append(feature.cpu().detach().numpy().reshape(-1,4096))\n",
    "# Convert to NumPy Array\n",
    "X_test = np.array(X_test)\n",
    "Y_test = np.array(Y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Embeddings as CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(X_train).to_csv(\"feature_csv/resnet18_x_train.csv\", index=False)  \n",
    "pd.DataFrame(Y_train).to_csv(\"feature_csv/resnet18_y_train.csv\", index=False)\n",
    "\n",
    "pd.DataFrame(X_test).to_csv(\"feature_csv/resnet18_x_test.csv\", index=False)  \n",
    "pd.DataFrame(Y_test).to_csv(\"feature_csv/resnet18_y_test.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the saved CSV's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(X_train).to_csv(\"feature_csv/vgg16_x_train.csv\", index=False)  \n",
    "# pd.DataFrame(Y_train).to_csv(\"feature_csv/vgg16_y_train.csv\", index=False)\n",
    "X_train = pd.read_csv(\"feature_csv/resnet18_x_train.csv\")\n",
    "Y_train = pd.read_csv(\"feature_csv/resnet18_y_train.csv\")\n",
    "\n",
    "# pd.DataFrame(X_test).to_csv(\"feature_csv/vgg16_x_test.csv\", index=False)  \n",
    "# pd.DataFrame(Y_test).to_csv(\"feature_csv/vgg16_y_test.csv\", index=False)\n",
    "X_test = pd.read_csv(\"feature_csv/resnet18_x_test.csv\")\n",
    "Y_test = pd.read_csv(\"feature_csv/resnet18_y_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.iloc[:,:].values\n",
    "Y_train = Y_train.iloc[:,:].values\n",
    "\n",
    "X_test = X_test.iloc[:,:].values\n",
    "Y_test = Y_test.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y_train = Y_train.reshape(-1,)\n",
    "# Y_test = Y_test.reshape(-1,)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(178732, 14)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0 (pos) is trained\n",
      "model 0 (neg) is trained\n",
      "model 0 is trained\n",
      "model 1 (pos) is trained\n",
      "model 1 (neg) is trained\n",
      "model 1 is trained\n",
      "model 2 (pos) is trained\n",
      "model 2 (neg) is trained\n",
      "model 2 is trained\n",
      "model 3 (pos) is trained\n",
      "model 3 (neg) is trained\n",
      "model 3 is trained\n",
      "model 4 (pos) is trained\n",
      "model 4 (neg) is trained\n",
      "model 4 is trained\n",
      "model 5 (pos) is trained\n",
      "model 5 (neg) is trained\n",
      "model 5 is trained\n",
      "model 6 (pos) is trained\n",
      "model 6 (neg) is trained\n",
      "model 6 is trained\n",
      "model 7 (pos) is trained\n",
      "model 7 (neg) is trained\n",
      "model 7 is trained\n",
      "model 8 (pos) is trained\n",
      "model 8 (neg) is trained\n",
      "model 8 is trained\n",
      "model 9 (pos) is trained\n",
      "model 9 (neg) is trained\n",
      "model 9 is trained\n",
      "model 10 (pos) is trained\n",
      "model 10 (neg) is trained\n",
      "model 10 is trained\n",
      "model 11 (pos) is trained\n",
      "model 11 (neg) is trained\n",
      "model 11 is trained\n",
      "model 12 (pos) is trained\n",
      "model 12 (neg) is trained\n",
      "model 12 is trained\n",
      "model 13 (pos) is trained\n",
      "model 13 (neg) is trained\n",
      "model 13 is trained\n"
     ]
    }
   ],
   "source": [
    "# pos_preds = []\n",
    "# neg_preds = []\n",
    "\n",
    "# pos_preds_probs = []\n",
    "# neg_preds_probs = []\n",
    "\n",
    "pos_scores = []\n",
    "neg_scores = []\n",
    "\n",
    "gmm_pos_models   = []\n",
    "gmm_neg_models   = []\n",
    "\n",
    "y_pred = np.zeros_like(Y_test)\n",
    "for i in range(14):\n",
    "    x_pos_train = X_train[Y_train[:, i] == 1]\n",
    "    x_neg_train = X_train[Y_train[:, i] == 0]\n",
    "    \n",
    "    gmm_pos = GaussianMixture(n_components=3,init_params='random',covariance_type='diag',tol=0.001).fit(x_pos_train)\n",
    "    print(\"model {} (pos) is trained\".format(i) )\n",
    "    \n",
    "    gmm_neg = GaussianMixture(n_components=3,init_params='kmeans',covariance_type='diag',tol=0.001).fit(x_neg_train)\n",
    "    print(\"model {} (neg) is trained\".format(i) )\n",
    "\n",
    "    pos_preds = gmm_pos.score_samples(X_test)\n",
    "    neg_preds = gmm_neg.score_samples(X_test)\n",
    "    \n",
    "    for j in range(pos_preds.shape[0]):\n",
    "        if pos_preds[j]>neg_preds[j]:\n",
    "            y_pred[j,i] = 1\n",
    "\n",
    "    gmm_pos_models.append(gmm_pos)\n",
    "    gmm_neg_models.append(gmm_neg)\n",
    "\n",
    "#     print(\"model {} is trained\".format(i) )\n",
    "print('Trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class 0: 0.05677901615863211\n",
      "Accuracy for class 1: 0.07085627321964102\n",
      "Accuracy for class 2: 0.10274831028154514\n",
      "Accuracy for class 3: 0.29188487534130075\n",
      "Accuracy for class 4: 0.02837831789087328\n",
      "Accuracy for class 5: 0.2129269056890918\n",
      "Accuracy for class 6: 0.15435745937961595\n",
      "Accuracy for class 7: 0.08186741864733002\n",
      "Accuracy for class 8: 0.2554272413947451\n",
      "Accuracy for class 9: 0.06369455261626605\n",
      "Accuracy for class 10: 0.274786267400743\n",
      "Accuracy for class 11: 0.02141802067946824\n",
      "Accuracy for class 12: 0.022581800277516672\n",
      "Accuracy for class 13: 0.337496083434045\n"
     ]
    }
   ],
   "source": [
    "# 3 componenets, Spherical Covariance\n",
    "for i in range(Y_test.shape[1]):\n",
    "    acc = sum(y_pred[:,i]*Y_test[:,i])\n",
    "    print('Accuracy for class {}: {}'.format(i,acc/Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pos_preds = []\n",
    "# neg_preds = []\n",
    "\n",
    "# pos_preds_probs = []\n",
    "# neg_preds_probs = []\n",
    "\n",
    "pos_scores = []\n",
    "neg_scores = []\n",
    "\n",
    "gmm_pos_models   = []\n",
    "gmm_neg_models   = []\n",
    "\n",
    "y_pred = np.zeros_like(Y_test)\n",
    "for i in range(14):\n",
    "    x_pos_train = X_train[Y_train[:, i] == 1]\n",
    "    x_neg_train = X_train[Y_train[:, i] == 0]\n",
    "    \n",
    "    gmm_pos = GaussianMixture(n_components=3,init_params='random',covariance_type='spherical',tol=0.001).fit(x_pos_train)\n",
    "    print(\"model {} (pos) is trained\".format(i) )\n",
    "    \n",
    "    gmm_neg = GaussianMixture(n_components=3,init_params='kmeans',covariance_type='spherical',tol=0.001).fit(x_neg_train)\n",
    "    print(\"model {} (neg) is trained\".format(i) )\n",
    "\n",
    "    pos_preds = gmm_pos.score_samples(X_test)\n",
    "    neg_preds = gmm_neg.score_samples(X_test)\n",
    "    \n",
    "    for j in range(pos_preds.shape[0]):\n",
    "        if pos_preds[j]>neg_preds[j]:\n",
    "            y_pred[j,i] = 1\n",
    "\n",
    "    gmm_pos_models.append(gmm_pos)\n",
    "    gmm_neg_models.append(gmm_neg)\n",
    "\n",
    "#     print(\"model {} is trained\".format(i) )\n",
    "print('Trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class 0: 0.05812183877176492\n",
      "Accuracy for class 1: 0.06783492234009221\n",
      "Accuracy for class 2: 0.10004028467839399\n",
      "Accuracy for class 3: 0.2964504722259523\n",
      "Accuracy for class 4: 0.027259299046595943\n",
      "Accuracy for class 5: 0.2167539501365203\n",
      "Accuracy for class 6: 0.1495904391029945\n",
      "Accuracy for class 7: 0.08012174925025738\n",
      "Accuracy for class 8: 0.24931739850499082\n",
      "Accuracy for class 9: 0.061187950405084825\n",
      "Accuracy for class 10: 0.27809856317980397\n",
      "Accuracy for class 11: 0.019940915805022157\n",
      "Accuracy for class 12: 0.022805604046372142\n",
      "Accuracy for class 13: 0.34163645315787117\n"
     ]
    }
   ],
   "source": [
    "# 3 componenets, Diagonal Covariance\n",
    "for i in range(Y_test.shape[1]):\n",
    "    acc = sum(y_pred[:,i]*Y_test[:,i])\n",
    "    print('Accuracy for class {}: {}'.format(i,acc/Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0 (pos) is trained\n",
      "model 0 (neg) is trained\n",
      "model 1 (pos) is trained\n",
      "model 1 (neg) is trained\n",
      "model 2 (pos) is trained\n",
      "model 2 (neg) is trained\n",
      "model 3 (pos) is trained\n",
      "model 3 (neg) is trained\n",
      "model 4 (pos) is trained\n",
      "model 4 (neg) is trained\n",
      "model 5 (pos) is trained\n",
      "model 5 (neg) is trained\n",
      "model 6 (pos) is trained\n",
      "model 6 (neg) is trained\n",
      "model 7 (pos) is trained\n",
      "model 7 (neg) is trained\n",
      "model 8 (pos) is trained\n",
      "model 8 (neg) is trained\n",
      "model 9 (pos) is trained\n",
      "model 9 (neg) is trained\n",
      "model 10 (pos) is trained\n",
      "model 10 (neg) is trained\n",
      "model 11 (pos) is trained\n",
      "model 11 (neg) is trained\n",
      "model 12 (pos) is trained\n",
      "model 12 (neg) is trained\n",
      "model 13 (pos) is trained\n",
      "model 13 (neg) is trained\n",
      "Trained\n"
     ]
    }
   ],
   "source": [
    "# pos_preds = []\n",
    "# neg_preds = []\n",
    "\n",
    "# pos_preds_probs = []\n",
    "# neg_preds_probs = []\n",
    "\n",
    "pos_scores = []\n",
    "neg_scores = []\n",
    "\n",
    "gmm_pos_models   = []\n",
    "gmm_neg_models   = []\n",
    "\n",
    "y_pred = np.zeros_like(Y_test)\n",
    "for i in range(14):\n",
    "    x_pos_train = X_train[Y_train[:, i] == 1]\n",
    "    x_neg_train = X_train[Y_train[:, i] == 0]\n",
    "    \n",
    "    gmm_pos = GaussianMixture(n_components=4,init_params='random',covariance_type='spherical',tol=0.001).fit(x_pos_train)\n",
    "    print(\"model {} (pos) is trained\".format(i) )\n",
    "    \n",
    "    gmm_neg = GaussianMixture(n_components=4,init_params='kmeans',covariance_type='spherical',tol=0.001).fit(x_neg_train)\n",
    "    print(\"model {} (neg) is trained\".format(i) )\n",
    "\n",
    "    pos_preds = gmm_pos.score_samples(X_test)\n",
    "    neg_preds = gmm_neg.score_samples(X_test)\n",
    "    \n",
    "    for j in range(pos_preds.shape[0]):\n",
    "        if pos_preds[j]>neg_preds[j]:\n",
    "            y_pred[j,i] = 1\n",
    "\n",
    "    gmm_pos_models.append(gmm_pos)\n",
    "    gmm_neg_models.append(gmm_neg)\n",
    "\n",
    "#     print(\"model {} is trained\".format(i) )\n",
    "print('Trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class 0: 0.05886039120898796\n",
      "Accuracy for class 1: 0.07018486191307462\n",
      "Accuracy for class 2: 0.10015218656282172\n",
      "Accuracy for class 3: 0.29347388210017455\n",
      "Accuracy for class 4: 0.028691643167270936\n",
      "Accuracy for class 5: 0.22152097041314175\n",
      "Accuracy for class 6: 0.1514703907613804\n",
      "Accuracy for class 7: 0.07985318472763081\n",
      "Accuracy for class 8: 0.24766125061546038\n",
      "Accuracy for class 9: 0.06253077301821763\n",
      "Accuracy for class 10: 0.27330916252629694\n",
      "Accuracy for class 11: 0.021261358041269416\n",
      "Accuracy for class 12: 0.023186070453426435\n",
      "Accuracy for class 13: 0.3344971129313818\n"
     ]
    }
   ],
   "source": [
    "# 4 componenets, spherical Covariance\n",
    "for i in range(Y_test.shape[1]):\n",
    "    acc = sum(y_pred[:,i]*Y_test[:,i])\n",
    "    print('Accuracy for class {}: {}'.format(i,acc/Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0 (pos) is trained\n",
      "model 0 (neg) is trained\n",
      "model 1 (pos) is trained\n",
      "model 1 (neg) is trained\n",
      "model 2 (pos) is trained\n",
      "model 2 (neg) is trained\n",
      "model 3 (pos) is trained\n",
      "model 3 (neg) is trained\n",
      "model 4 (pos) is trained\n",
      "model 4 (neg) is trained\n",
      "model 5 (pos) is trained\n",
      "model 5 (neg) is trained\n",
      "model 6 (pos) is trained\n",
      "model 6 (neg) is trained\n",
      "model 7 (pos) is trained\n",
      "model 7 (neg) is trained\n",
      "model 8 (pos) is trained\n",
      "model 8 (neg) is trained\n",
      "model 9 (pos) is trained\n",
      "model 9 (neg) is trained\n",
      "model 10 (pos) is trained\n",
      "model 10 (neg) is trained\n",
      "model 11 (pos) is trained\n",
      "model 11 (neg) is trained\n",
      "model 12 (pos) is trained\n",
      "model 12 (neg) is trained\n",
      "model 13 (pos) is trained\n",
      "model 13 (neg) is trained\n",
      "Trained\n"
     ]
    }
   ],
   "source": [
    "# pos_preds = []\n",
    "# neg_preds = []\n",
    "\n",
    "# pos_preds_probs = []\n",
    "# neg_preds_probs = []\n",
    "\n",
    "pos_scores = []\n",
    "neg_scores = []\n",
    "\n",
    "gmm_pos_models   = []\n",
    "gmm_neg_models   = []\n",
    "\n",
    "y_pred = np.zeros_like(Y_test)\n",
    "for i in range(14):\n",
    "    x_pos_train = X_train[Y_train[:, i] == 1]\n",
    "    x_neg_train = X_train[Y_train[:, i] == 0]\n",
    "\n",
    "    \n",
    "    gmm_pos = GaussianMixture(n_components=4,init_params='random',covariance_type='diag',tol=0.001).fit(x_pos_train)\n",
    "    print(\"model {} (pos) is trained\".format(i) )\n",
    "    \n",
    "    gmm_neg = GaussianMixture(n_components=4,init_params='kmeans',covariance_type='diag',tol=0.001).fit(x_neg_train)\n",
    "    print(\"model {} (neg) is trained\".format(i) )\n",
    "\n",
    "    pos_preds = gmm_pos.score_samples(X_test)\n",
    "    neg_preds = gmm_neg.score_samples(X_test)\n",
    "    \n",
    "    for j in range(pos_preds.shape[0]):\n",
    "        if pos_preds[j]>neg_preds[j]:\n",
    "            y_pred[j,i] = 1\n",
    "\n",
    "    gmm_pos_models.append(gmm_pos)\n",
    "    gmm_neg_models.append(gmm_neg)\n",
    "\n",
    "#     print(\"model {} is trained\".format(i) )\n",
    "print('Trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class 0: 0.05950942213866881\n",
      "Accuracy for class 1: 0.07172910791817734\n",
      "Accuracy for class 2: 0.10035360995479164\n",
      "Accuracy for class 3: 0.2920862987332707\n",
      "Accuracy for class 4: 0.02486459871984244\n",
      "Accuracy for class 5: 0.21731345955865897\n",
      "Accuracy for class 6: 0.14600957880130702\n",
      "Accuracy for class 7: 0.07358667919967772\n",
      "Accuracy for class 8: 0.24358802202229085\n",
      "Accuracy for class 9: 0.06042701759097623\n",
      "Accuracy for class 10: 0.27662145830535784\n",
      "Accuracy for class 11: 0.018351909046148338\n",
      "Accuracy for class 12: 0.02141802067946824\n",
      "Accuracy for class 13: 0.33740656192650287\n"
     ]
    }
   ],
   "source": [
    "# 4 componenets, Diagonal Covariance\n",
    "for i in range(Y_test.shape[1]):\n",
    "    acc = sum(y_pred[:,i]*Y_test[:,i])\n",
    "    print('Accuracy for class {}: {}'.format(i,acc/Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0 (pos) is trained\n",
      "model 0 (neg) is trained\n",
      "model 1 (pos) is trained\n",
      "model 1 (neg) is trained\n",
      "model 2 (pos) is trained\n",
      "model 2 (neg) is trained\n",
      "model 3 (pos) is trained\n",
      "model 3 (neg) is trained\n",
      "model 4 (pos) is trained\n",
      "model 4 (neg) is trained\n",
      "model 5 (pos) is trained\n",
      "model 5 (neg) is trained\n",
      "model 6 (pos) is trained\n",
      "model 6 (neg) is trained\n",
      "model 7 (pos) is trained\n",
      "model 7 (neg) is trained\n",
      "model 8 (pos) is trained\n",
      "model 8 (neg) is trained\n",
      "model 9 (pos) is trained\n",
      "model 9 (neg) is trained\n",
      "model 10 (pos) is trained\n",
      "model 10 (neg) is trained\n",
      "model 11 (pos) is trained\n",
      "model 11 (neg) is trained\n",
      "model 12 (pos) is trained\n",
      "model 12 (neg) is trained\n",
      "model 13 (pos) is trained\n",
      "model 13 (neg) is trained\n",
      "Trained\n"
     ]
    }
   ],
   "source": [
    "# pos_preds = []\n",
    "# neg_preds = []\n",
    "\n",
    "# pos_preds_probs = []\n",
    "# neg_preds_probs = []\n",
    "\n",
    "pos_scores = []\n",
    "neg_scores = []\n",
    "\n",
    "gmm_pos_models   = []\n",
    "gmm_neg_models   = []\n",
    "\n",
    "y_pred = np.zeros_like(Y_test)\n",
    "for i in range(14):\n",
    "    x_pos_train = X_train[Y_train[:, i] == 1]\n",
    "    x_neg_train = X_train[Y_train[:, i] == 0]\n",
    "\n",
    "    gmm_pos = GaussianMixture(n_components=2,init_params='random',covariance_type='diag',tol=0.001).fit(x_pos_train)\n",
    "    print(\"model {} (pos) is trained\".format(i) )\n",
    "    \n",
    "    gmm_neg = GaussianMixture(n_components=2,init_params='kmeans',covariance_type='diag',tol=0.001).fit(x_neg_train)\n",
    "    print(\"model {} (neg) is trained\".format(i) )\n",
    "\n",
    "    pos_preds = gmm_pos.score_samples(X_test)\n",
    "    neg_preds = gmm_neg.score_samples(X_test)\n",
    "    \n",
    "    for j in range(pos_preds.shape[0]):\n",
    "        if pos_preds[j]>neg_preds[j]:\n",
    "            y_pred[j,i] = 1\n",
    "\n",
    "    gmm_pos_models.append(gmm_pos)\n",
    "    gmm_neg_models.append(gmm_neg)\n",
    "\n",
    "#     print(\"model {} is trained\".format(i) )\n",
    "print('Trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class 0: 0.061568416812139114\n",
      "Accuracy for class 1: 0.0661563940736762\n",
      "Accuracy for class 2: 0.0974665413365561\n",
      "Accuracy for class 3: 0.2832012891097086\n",
      "Accuracy for class 4: 0.028512600152186564\n",
      "Accuracy for class 5: 0.20592184772391567\n",
      "Accuracy for class 6: 0.1478223893290363\n",
      "Accuracy for class 7: 0.0816659952553601\n",
      "Accuracy for class 8: 0.24580367933396\n",
      "Accuracy for class 9: 0.062217447741819976\n",
      "Accuracy for class 10: 0.271675395013652\n",
      "Accuracy for class 11: 0.0206794682422452\n",
      "Accuracy for class 12: 0.023767960252450652\n",
      "Accuracy for class 13: 0.33315429031824895\n"
     ]
    }
   ],
   "source": [
    "# 2 componenets, Diagonal Covariance\n",
    "for i in range(Y_test.shape[1]):\n",
    "    acc = sum(y_pred[:,i]*Y_test[:,i])\n",
    "    print('Accuracy for class {}: {}'.format(i,acc/Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0 (pos) is trained\n",
      "model 0 (neg) is trained\n",
      "model 1 (pos) is trained\n",
      "model 1 (neg) is trained\n",
      "model 2 (pos) is trained\n",
      "model 2 (neg) is trained\n",
      "model 3 (pos) is trained\n",
      "model 3 (neg) is trained\n",
      "model 4 (pos) is trained\n",
      "model 4 (neg) is trained\n",
      "model 5 (pos) is trained\n",
      "model 5 (neg) is trained\n",
      "model 6 (pos) is trained\n",
      "model 6 (neg) is trained\n",
      "model 7 (pos) is trained\n",
      "model 7 (neg) is trained\n",
      "model 8 (pos) is trained\n",
      "model 8 (neg) is trained\n",
      "model 9 (pos) is trained\n",
      "model 9 (neg) is trained\n",
      "model 10 (pos) is trained\n",
      "model 10 (neg) is trained\n",
      "model 11 (pos) is trained\n",
      "model 11 (neg) is trained\n",
      "model 12 (pos) is trained\n",
      "model 12 (neg) is trained\n",
      "model 13 (pos) is trained\n",
      "model 13 (neg) is trained\n",
      "Trained\n"
     ]
    }
   ],
   "source": [
    "# pos_preds = []\n",
    "# neg_preds = []\n",
    "\n",
    "# pos_preds_probs = []\n",
    "# neg_preds_probs = []\n",
    "\n",
    "pos_scores = []\n",
    "neg_scores = []\n",
    "\n",
    "gmm_pos_models   = []\n",
    "gmm_neg_models   = []\n",
    "\n",
    "y_pred = np.zeros_like(Y_test)\n",
    "for i in range(14):\n",
    "    x_pos_train = X_train[Y_train[:, i] == 1]\n",
    "    x_neg_train = X_train[Y_train[:, i] == 0]\n",
    "    \n",
    "    gmm_pos = GaussianMixture(n_components=2,init_params='random',covariance_type='spherical',tol=0.001).fit(x_pos_train)\n",
    "    print(\"model {} (pos) is trained\".format(i) )\n",
    "    \n",
    "    gmm_neg = GaussianMixture(n_components=2,init_params='kmeans',covariance_type='spherical',tol=0.001).fit(x_neg_train)\n",
    "    print(\"model {} (neg) is trained\".format(i) )\n",
    "\n",
    "    pos_preds = gmm_pos.score_samples(X_test)\n",
    "    neg_preds = gmm_neg.score_samples(X_test)\n",
    "    \n",
    "    for j in range(pos_preds.shape[0]):\n",
    "        if pos_preds[j]>neg_preds[j]:\n",
    "            y_pred[j,i] = 1\n",
    "\n",
    "    gmm_pos_models.append(gmm_pos)\n",
    "    gmm_neg_models.append(gmm_neg)\n",
    "\n",
    "#     print(\"model {} is trained\".format(i) )\n",
    "print('Trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class 0: 0.06235173000313325\n",
      "Accuracy for class 1: 0.07016248153618906\n",
      "Accuracy for class 2: 0.09997314354773734\n",
      "Accuracy for class 3: 0.1778792354863256\n",
      "Accuracy for class 4: 0.0296316189964639\n",
      "Accuracy for class 5: 0.20283335571371022\n",
      "Accuracy for class 6: 0.15191799829909136\n",
      "Accuracy for class 7: 0.08882771585873506\n",
      "Accuracy for class 8: 0.25157781657043105\n",
      "Accuracy for class 9: 0.06396311713889262\n",
      "Accuracy for class 10: 0.2695716395864106\n",
      "Accuracy for class 11: 0.021888008594064725\n",
      "Accuracy for class 12: 0.024707936081643615\n",
      "Accuracy for class 13: 0.3304462647150978\n"
     ]
    }
   ],
   "source": [
    "# 2 componenets, spherical Covariance\n",
    "for i in range(Y_test.shape[1]):\n",
    "    acc = sum(y_pred[:,i]*Y_test[:,i])\n",
    "    print('Accuracy for class {}: {}'.format(i,acc/Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0 (pos) is trained\n",
      "model 0 (neg) is trained\n",
      "model 1 (pos) is trained\n",
      "model 1 (neg) is trained\n",
      "model 2 (pos) is trained\n",
      "model 2 (neg) is trained\n",
      "model 3 (pos) is trained\n",
      "model 3 (neg) is trained\n",
      "model 4 (pos) is trained\n",
      "model 4 (neg) is trained\n",
      "model 5 (pos) is trained\n",
      "model 5 (neg) is trained\n",
      "model 6 (pos) is trained\n",
      "model 6 (neg) is trained\n",
      "model 7 (pos) is trained\n",
      "model 7 (neg) is trained\n",
      "model 8 (pos) is trained\n",
      "model 8 (neg) is trained\n",
      "model 9 (pos) is trained\n",
      "model 9 (neg) is trained\n",
      "model 10 (pos) is trained\n",
      "model 10 (neg) is trained\n",
      "model 11 (pos) is trained\n",
      "model 11 (neg) is trained\n",
      "model 12 (pos) is trained\n",
      "model 12 (neg) is trained\n",
      "model 13 (pos) is trained\n",
      "model 13 (neg) is trained\n",
      "Trained\n"
     ]
    }
   ],
   "source": [
    "# pos_preds = []\n",
    "# neg_preds = []\n",
    "\n",
    "# pos_preds_probs = []\n",
    "# neg_preds_probs = []\n",
    "\n",
    "pos_scores = []\n",
    "neg_scores = []\n",
    "\n",
    "gmm_pos_models   = []\n",
    "gmm_neg_models   = []\n",
    "\n",
    "y_pred = np.zeros_like(Y_test)\n",
    "for i in range(14):\n",
    "    x_pos_train = X_train[Y_train[:, i] == 1]\n",
    "    x_neg_train = X_train[Y_train[:, i] == 0]\n",
    "    \n",
    "    gmm_pos = GaussianMixture(n_components=3,init_params='random',covariance_type='spherical',tol=0.001).fit(x_pos_train)\n",
    "    print(\"model {} (pos) is trained\".format(i) )\n",
    "    \n",
    "    gmm_neg = GaussianMixture(n_components=6,init_params='kmeans',covariance_type='spherical',tol=0.001).fit(x_neg_train)\n",
    "    print(\"model {} (neg) is trained\".format(i) )\n",
    "\n",
    "    pos_preds = gmm_pos.score_samples(X_test)\n",
    "    neg_preds = gmm_neg.score_samples(X_test)\n",
    "    \n",
    "    for j in range(pos_preds.shape[0]):\n",
    "        if pos_preds[j]>neg_preds[j]:\n",
    "            y_pred[j,i] = 1\n",
    "\n",
    "    gmm_pos_models.append(gmm_pos)\n",
    "    gmm_neg_models.append(gmm_neg)\n",
    "\n",
    "#     print(\"model {} is trained\".format(i) )\n",
    "print('Trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class 0: 0.04626023902242514\n",
      "Accuracy for class 1: 0.05841278367127702\n",
      "Accuracy for class 2: 0.07571281500380467\n",
      "Accuracy for class 3: 0.21892484669441833\n",
      "Accuracy for class 4: 0.01839666979991943\n",
      "Accuracy for class 5: 0.1719484356116557\n",
      "Accuracy for class 6: 0.11986929859898841\n",
      "Accuracy for class 7: 0.06532832012891097\n",
      "Accuracy for class 8: 0.18407859988362205\n",
      "Accuracy for class 9: 0.04661832505259388\n",
      "Accuracy for class 10: 0.21207645136744102\n",
      "Accuracy for class 11: 0.015106754397744058\n",
      "Accuracy for class 12: 0.016516718141533503\n",
      "Accuracy for class 13: 0.2825298778031422\n"
     ]
    }
   ],
   "source": [
    "# 2 componenets, spherical Covariance\n",
    "for i in range(Y_test.shape[1]):\n",
    "    acc = sum(y_pred[:,i]*Y_test[:,i])\n",
    "    print('Accuracy for class {}: {}'.format(i,acc/Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 0 (pos) is trained\n",
      "model 0 (neg) is trained\n",
      "model 1 (pos) is trained\n",
      "model 1 (neg) is trained\n",
      "model 2 (pos) is trained\n",
      "model 2 (neg) is trained\n",
      "model 3 (pos) is trained\n",
      "model 3 (neg) is trained\n",
      "model 4 (pos) is trained\n",
      "model 4 (neg) is trained\n",
      "model 5 (pos) is trained\n",
      "model 5 (neg) is trained\n",
      "model 6 (pos) is trained\n",
      "model 6 (neg) is trained\n",
      "model 7 (pos) is trained\n",
      "model 7 (neg) is trained\n",
      "model 8 (pos) is trained\n",
      "model 8 (neg) is trained\n",
      "model 9 (pos) is trained\n",
      "model 9 (neg) is trained\n",
      "model 10 (pos) is trained\n",
      "model 10 (neg) is trained\n",
      "model 11 (pos) is trained\n",
      "model 11 (neg) is trained\n",
      "model 12 (pos) is trained\n",
      "model 12 (neg) is trained\n",
      "model 13 (pos) is trained\n",
      "model 13 (neg) is trained\n",
      "Trained\n"
     ]
    }
   ],
   "source": [
    "# pos_preds = []\n",
    "# neg_preds = []\n",
    "\n",
    "# pos_preds_probs = []\n",
    "# neg_preds_probs = []\n",
    "\n",
    "pos_scores = []\n",
    "neg_scores = []\n",
    "\n",
    "gmm_pos_models   = []\n",
    "gmm_neg_models   = []\n",
    "\n",
    "y_pred = np.zeros_like(Y_test)\n",
    "for i in range(14):\n",
    "    x_pos_train = X_train[Y_train[:, i] == 1]\n",
    "    x_neg_train = X_train[Y_train[:, i] == 0]\n",
    "    \n",
    "    gmm_pos = GaussianMixture(n_components=3,init_params='random',covariance_type='spherical',tol=0.001).fit(x_pos_train)\n",
    "    print(\"model {} (pos) is trained\".format(i) )\n",
    "    \n",
    "    gmm_neg = GaussianMixture(n_components=6,init_params='kmeans',covariance_type='spherical',tol=0.001).fit(x_neg_train)\n",
    "    print(\"model {} (neg) is trained\".format(i) )\n",
    "\n",
    "    pos_preds = gmm_pos.score_samples(X_test)\n",
    "    neg_preds = gmm_neg.score_samples(X_test)\n",
    "    \n",
    "    for j in range(pos_preds.shape[0]):\n",
    "        if pos_preds[j]>neg_preds[j]:\n",
    "            y_pred[j,i] = 1\n",
    "\n",
    "    gmm_pos_models.append(gmm_pos)\n",
    "    gmm_neg_models.append(gmm_neg)\n",
    "\n",
    "#     print(\"model {} is trained\".format(i) )\n",
    "print('Trained')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for class 0: 0.04305984512779195\n",
      "Accuracy for class 1: 0.058144219148650464\n",
      "Accuracy for class 2: 0.07522044671232264\n",
      "Accuracy for class 3: 0.22861554988586008\n",
      "Accuracy for class 4: 0.020164719573877624\n",
      "Accuracy for class 5: 0.1716127299583725\n",
      "Accuracy for class 6: 0.11962311445324739\n",
      "Accuracy for class 7: 0.06503737522939887\n",
      "Accuracy for class 8: 0.18392193724542322\n",
      "Accuracy for class 9: 0.046819748444563804\n",
      "Accuracy for class 10: 0.21180788684481447\n",
      "Accuracy for class 11: 0.015218656282171792\n",
      "Accuracy for class 12: 0.01653909851841905\n",
      "Accuracy for class 13: 0.25795622398281187\n"
     ]
    }
   ],
   "source": [
    "# 2 componenets, spherical Covariance\n",
    "for i in range(Y_test.shape[1]):\n",
    "    acc = sum(y_pred[:,i]*Y_test[:,i])\n",
    "    print('Accuracy for class {}: {}'.format(i,acc/Y_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
